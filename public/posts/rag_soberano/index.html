<!--
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

- -->
<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="Como construí meu próprio RAG soberano para análise de segurança de código"><meta property="og:description" content="Construindo meu próprio RAG soberano para análise de segurança de código
Nos últimos tempos, comecei a olhar com mais atenção para algumas ferramentas de análise de código que prometem identificar falhas de segurança em projetos. A ideia é boa. Recebi uma dessas ferramentas como sugestão e fui atrás para entender melhor o que havia por trás da proposta.
Logo de cara percebi um padrão: os preços dessas plataformas não são exatamente convidativos. Algumas até oferecem planos gratuitos limitados, mas a gente sabe como funciona o jogo. Quando algo muito bom aparece “de graça”, o custo real costuma vir de outro lugar. Coleta de dados, lock-in na plataforma, modelos black-box processando seu código na nuvem de terceiros. E como hoje eu venho estudando bastante IA e, em especial, o tema dos RAGs (Retrieval-Augmented Generation), a pergunta veio automática: por que não montar o meu próprio pipeline, 100% local, soberano, usando ferramentas open-source, rodando direto na minha máquina, sem depender de ninguém?"><meta property="og:url" content="https://adlermedrado.com.br/posts/rag_soberano/"><meta property="og:site_name" content="Adler Medrado's corner of the web"><meta property="og:type" content="article"><meta property="og:image" content="/images/default-og-image.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Como construí meu próprio RAG soberano para análise de segurança de código"><meta name=twitter:description content="Construindo meu próprio RAG soberano para análise de segurança de código
Nos últimos tempos, comecei a olhar com mais atenção para algumas ferramentas de análise de código que prometem identificar falhas de segurança em projetos. A ideia é boa. Recebi uma dessas ferramentas como sugestão e fui atrás para entender melhor o que havia por trás da proposta.
Logo de cara percebi um padrão: os preços dessas plataformas não são exatamente convidativos. Algumas até oferecem planos gratuitos limitados, mas a gente sabe como funciona o jogo. Quando algo muito bom aparece “de graça”, o custo real costuma vir de outro lugar. Coleta de dados, lock-in na plataforma, modelos black-box processando seu código na nuvem de terceiros. E como hoje eu venho estudando bastante IA e, em especial, o tema dos RAGs (Retrieval-Augmented Generation), a pergunta veio automática: por que não montar o meu próprio pipeline, 100% local, soberano, usando ferramentas open-source, rodando direto na minha máquina, sem depender de ninguém?"><meta name=twitter:image content="/images/default-og-image.png"><title>Como construí meu próprio RAG soberano para análise de segurança de código</title><meta name=description content="Construindo meu próprio RAG soberano para análise de segurança de código
Nos últimos tempos, comecei a olhar com mais atenção para algumas ferramentas de análise de código que prometem identificar falhas de segurança em projetos. A ideia é boa. Recebi uma dessas ferramentas como sugestão e fui atrás para entender melhor o que havia por trás da proposta.
Logo de cara percebi um padrão: os preços dessas plataformas não são exatamente convidativos. Algumas até oferecem planos gratuitos limitados, mas a gente sabe como funciona o jogo. Quando algo muito bom aparece “de graça”, o custo real costuma vir de outro lugar. Coleta de dados, lock-in na plataforma, modelos black-box processando seu código na nuvem de terceiros. E como hoje eu venho estudando bastante IA e, em especial, o tema dos RAGs (Retrieval-Augmented Generation), a pergunta veio automática: por que não montar o meu próprio pipeline, 100% local, soberano, usando ferramentas open-source, rodando direto na minha máquina, sem depender de ninguém?"><link rel=author href=/humans.txt><link rel=icon type=image/png href=/images/favicon.png><link rel=canonical href=https://adlermedrado.com.br/posts/rag_soberano/><link href=/css/styles.css rel=stylesheet></head><body><header class=glitch-zone><nav class=navbar role=navigation aria-label="Main Navigation"><div class=navbar_left><a href=/ class=h-card rel=me><strong>Adler Medrado<span class=cursor-blink>|</span></strong></a></div><div class="navbar_right navbar_right_animated"><a href=/posts>posts</a>
<a href=/missives>missives</a>
<a href=/now>what am i doing now</a>
<a href=/uses>what am i using</a></div></nav></header><main><section class=section><article><div><h1>Como construí meu próprio RAG soberano para análise de segurança de código</h1><div><div><p><small><time>June 14, 2025</time>
|
7 minutes read</small><div class=post-tags><p><strong>Tags:</strong>
<a href=/tags/rag>rag</a>,
<a href=/tags/ai>ai</a>,
<a href=/tags/ia>ia</a>,
<a href=/tags/soberania>soberania</a>,
<a href=/tags/ollama>ollama</a>,
<a href=/tags/llm>llm</a>,
<a href=/tags/seguranca>seguranca</a></p></div></p></div><span class=line_break></span></div><div class=content><h2 id=construindo-meu-próprio-rag-soberano-para-análise-de-segurança-de-código>Construindo meu próprio RAG soberano para análise de segurança de código</h2><p>Nos últimos tempos, comecei a olhar com mais atenção para algumas ferramentas de análise de código que prometem identificar falhas de segurança em projetos. A ideia é boa. Recebi uma dessas ferramentas como sugestão e fui atrás para entender melhor o que havia por trás da proposta.</p><p>Logo de cara percebi um padrão: os preços dessas plataformas não são exatamente convidativos. Algumas até oferecem planos gratuitos limitados, mas a gente sabe como funciona o jogo. Quando algo muito bom aparece “de graça”, o custo real costuma vir de outro lugar. Coleta de dados, lock-in na plataforma, modelos black-box processando seu código na nuvem de terceiros. E como hoje eu venho estudando bastante IA e, em especial, o tema dos RAGs (Retrieval-Augmented Generation), a pergunta veio automática: por que não montar o meu próprio pipeline, 100% local, soberano, usando ferramentas open-source, rodando direto na minha máquina, sem depender de ninguém?</p><p>Assim nasceu o <strong><a href=https://github.com/spacexnu/sovereign-rag>SovereignRAG</a></strong>.</p><h3 id=como-funciona>Como funciona</h3><p>A ideia básica foi simples: alimentar o meu RAG com conhecimento técnico sólido vindo de fontes reconhecidas na área de segurança. Fui direto em materiais como o OWASP Top 10, CWE, NIST e outras referências do setor. A partir daí, montei a seguinte estratégia:</p><ol><li>Coletar as fontes originais em PDF (OWASP Top 10, CWE, NIST, etc).</li><li>Criar um parser que faz a extração de texto desses PDFs. Para limpar o material, utilizei NLP com spaCy, removendo ruídos e filtrando o que realmente interessava. O resultado desse processamento foi persistido no ChromaDB como banco vetorial.</li><li>Desenvolver um prompt específico, já hardcoded inicialmente no projeto. O próximo passo natural aqui é tornar esse prompt dinâmico, parametrizável, para deixar a ferramenta mais flexível e adaptável a diferentes contextos.</li><li>Como motor de linguagem, escolhi o Ollama rodando localmente com o modelo mistral:7b-instruct. Não é um modelo gigantesco, mas também não é tão limitado como o phi3-instruct que inicialmente testei. Dentro da limitação de hardware, foi o melhor equilíbrio que encontrei.</li></ol><p>Estou rodando tudo isso no meu MacBook Air M1 com 16GB de RAM. É óbvio que o processo não é instantâneo. Inferência de LLM local consome CPU pesado, ainda mais quando começa a trabalhar com inputs longos e contexto técnico denso. Mas o ponto central do experimento foi provado: é perfeitamente viável rodar um pipeline de RAG soberano, offline, mantendo meus dados sob controle total, sem enviar nada para nuvem de ninguém, e principalmente, sem pagar o preço absurdo dessas soluções SaaS “inteligentes” que estão pipocando por aí.</p><p>Tenho várias melhorias mapeadas na minha cabeça. Paralelismo não está nos planos por enquanto, justamente porque não pretendo transformar o SSD do meu Mac em carvão swapando como se não houvesse amanhã.</p><h3 id=arquitetura-técnica>Arquitetura Técnica</h3><p>Como a ideia sempre foi manter o controle completo do pipeline, a arquitetura do SovereignRAG foi montada de forma modular, com cada etapa bem definida e com ferramentas open-source que eu mesmo pudesse operar localmente. Nada de dependência de serviços externos.</p><p>O pipeline ficou assim:</p><p><strong>1. Ingestão dos documentos de segurança</strong></p><p>A primeira etapa foi coletar e processar a base de conhecimento que alimentaria o RAG. Usei documentos oficiais de segurança no formato PDF, incluindo OWASP Top 10, CWE e NIST. Para extrair o conteúdo relevante, utilizei o PyMuPDF para fazer o parsing dos PDFs e o spaCy para limpeza, tokenização e remoção de informações irrelevantes. Essa etapa é importante porque qualquer ruído desnecessário impacta diretamente a qualidade dos embeddings gerados depois.</p><p><strong>2. Embeddings e indexação vetorial</strong></p><p>Com o conteúdo limpo em mãos, utilizei o modelo all-MiniLM-L6-v2 do SentenceTransformers para gerar os embeddings. Esses vetores foram armazenados no ChromaDB, um banco de dados vetorial leve e eficiente, que roda tranquilamente em máquina local sem exigir recursos absurdos.</p><p><strong>3. Query e análise de código</strong></p><p>No modo de análise de código, o pipeline lê o arquivo fonte, injeta o conteúdo no prompt já pré-definido, recupera os documentos mais relevantes do banco vetorial (top_k controlado para não sobrecarregar o modelo) e dispara a inferência.</p><p>A inferência roda localmente via Ollama, onde estou utilizando o modelo mistral:7b-instruct. Esse modelo foi o melhor equilíbrio que encontrei entre capacidade de raciocínio, suporte a contexto mais longo e viabilidade de rodar no hardware limitado que estou usando.</p><p><strong>4. Geração de relatório</strong></p><p>Para não ficar apenas no terminal, decidi gerar relatórios HTML com o resultado da análise de cada arquivo. Assim, além de permitir revisar o output com mais calma, também já abro espaço para no futuro transformar isso numa interface web mais organizada.</p><h3 id=desafios-limitações-e-lições-aprendidas>Desafios, Limitações e Lições Aprendidas</h3><p>Obviamente não existe mágica nessa história. Rodar um pipeline de RAG local, offline e soberano, com análise de código em cima de bases complexas de segurança, tem um conjunto bem claro de desafios. Não é o tipo de solução plug-and-play que os SaaS vendem, e também não é para qualquer perfil técnico.</p><p>O primeiro ponto que bate logo de cara é o próprio hardware. Rodar LLMs exige processamento pesado. Estou rodando tudo isso num MacBook Air M1 com 16GB de RAM, que é uma máquina excelente para muita coisa, mas está longe de ser um equipamento desenhado para processamento de inferência de IA em larga escala. Isso me forçou a tomar decisões bem pragmáticas desde o início: processamento serial (um arquivo por vez), controle rígido sobre o tamanho do contexto (top_k ajustado com cautela), chunking agressivo nos documentos durante a ingestão, e claro, nada de paralelismo. Paralelizar nesse contexto seria simplesmente suicídio térmico e desgaste desnecessário do SSD swapando sem parar.</p><p>Outro desafio importante é o próprio comportamento dos LLMs quando recebem contexto técnico muito denso. Aprendi rápido que não adianta simplesmente injetar documentação inteira e esperar que o modelo resolva tudo sozinho. Existe um trabalho delicado de engenharia de prompt aqui, para guiar o modelo na direção certa sem sobrecarregar o raciocínio dele com ruído desnecessário.</p><p>Além disso, o próprio balanceamento entre embedding de qualidade e performance de inferência local é um ponto que exige testes práticos. O modelo MiniLM foi uma boa escolha inicial para gerar embeddings compactos e eficientes, mas já vejo espaço para experimentar embeddings ainda mais otimizados no futuro (BGE, Instructor, etc).</p><p>Por fim, o mais óbvio de todos: velocidade. Não tem como rodar isso localmente e esperar tempos de resposta instantâneos, ainda mais com modelos de 7B. A cada análise, é preciso ter um pouco de paciência. Não é o tipo de ferramenta para integrar num fluxo de CI/CD ainda, mas como laboratório e prova de conceito soberano, cumpre o seu papel com excelência.</p><img height=50% src=/posts/images/sovereign-rag.png width=50%><h3 id=próximos-passos-e-evolução-do-projeto>Próximos passos e evolução do projeto</h3><p>O SovereignRAG nasceu como um laboratório, mas já começa a apontar caminhos interessantes para expansão. A arquitetura atual é funcional e cumpre bem o propósito de validar o conceito de RAG soberano aplicado à segurança de código, mas existem várias camadas de melhorias que pretendo implementar nas próximas etapas.</p><p>O primeiro ponto da lista é refinar ainda mais o chunking durante a ingestão dos documentos. Esse é um dos fatores mais críticos na construção de qualquer pipeline de RAG. Chunk errado, contexto errado. Existe um trabalho fino aqui para encontrar o melhor equilíbrio entre granularidade dos chunks, qualidade dos embeddings e capacidade de recall do vector store.</p><p>Outro ponto natural de evolução está nos próprios embeddings. Hoje estou usando o all-MiniLM-L6-v2 por uma questão de leveza e viabilidade no meu ambiente atual, mas já estou de olho em modelos mais sofisticados como o BGE e o Instructor, que podem oferecer embeddings semanticamente mais precisos para o tipo de dado que estou trabalhando.</p><p>Do lado da inferência, há espaço para experimentar outros modelos além do mistral:7b-instruct. Eventualmente posso validar o Mixtral ou até mesmo trabalhar com quantizações otimizadas que permitam melhorar a performance no hardware limitado. Também não descarto no futuro montar um pequeno servidor soberano dedicado só para rodar esse tipo de workload de forma mais fluida, preservando o MacBook para as tarefas de desenvolvimento e produção de conteúdo.</p><p>Outro objetivo de curto prazo é tornar o pipeline um pouco mais flexível e parametrizável. Hoje o prompt está hardcoded dentro do código. A ideia é abrir essa configuração, permitir ajustes mais fáceis, talvez até implementar templates de análise para diferentes tipos de projeto ou linguagem.</p><p>Por fim, o grande movimento de médio prazo envolve transformar o que hoje é um laboratório em um produto real. O SovereignRAG já serve de embrião para o que pode vir a ser o CodeTalon, um produto fechado, profissional, preparado para atuar em ambientes de segurança corporativa com análise de código soberana, offline e privada, sem depender de APIs de terceiros, nuvens obscuras ou SaaS engessados.</p><p>O conceito está plantado. Agora é seguir no aprimoramento técnico e deixar a máquina cada vez mais afiada.</p><p><img src=/posts/images/sovereign-rag-faster.gif alt=gif-version-of-video-running-the-rag></p></div></div></article><div><div><div><a href=https://adlermedrado.com.br/posts/deepfakes_realtime/>&#8592; Real-time Deepfakes: what if "seeing is believing" no longer means anything?</a>
|
<a href=https://adlermedrado.com.br/posts/sovereign-rag/>Building My Own Sovereign RAG for Secure Code Analysis &#8594;</a></div></div></div></section></main><footer class=glitch-zone role=contentinfo><div class=footer-content><div class=copyright><p><small>&copy; 1996-2025 Adler Medrado</small></p></div><div class=gpg_signed_info><p>All pages on this website are PGP signed.
Import my <a href=/pub-key.asc aria-label="Download my PGP public key">public key</a> and check with <em>curl https://adlermedrado.com.br/posts/rag_soberano/ | gpg --verify</em></p><p><em>Privacy policy: this website employs no tracking.</em></p><p><span class=badge-a-plus><a href="https://developer.mozilla.org/en-US/observatory/analyze?host=adlermedrado.com.br" aria-label="Mozilla Observatory Security Rating: A+">A+</a></span>
<span class=badge-description>Mozilla Observatory Security Rating</span></p></div></div></footer></body></html><!--
-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEB9cP28xEbBnKQwLObV8aePHcNh0FAmhUfwsACgkQbV8aePHc
Nh27fQ//bJ0qd4yOYj0k+qbjoJ8qO2Y042hPdBdYf1FZdnbjT6KHGZM3Ka1Tgf6Z
0wROs6RIn3gM1hsmXOSEX+GnUY85cl1uqZ8IqgF66v3uqJrhH57GVJ4tkpWgZOtb
9avxAZXgQ1r/QoCBDTkpJd1KtUAfC643uE8eDAzpwwlBEFohlVJ3Pm1zET659lSJ
vfjQkCwNKTL2FNo7TesIhbQfGm5r/39yt7clinogUDX97kmL3vPVvsRh07/tUhvy
baGWjVUfm1BUla+QUJDIWuJu+A6iKwe/jM6PHPtsEMJ97gAjS3WNah6WEHIF49xz
DtjaxuSKgesfp94cZnD1Sgc8OJ+ResZMOeTmB1K7YNSXgphQSLuZBtL+RM7scM7U
7Z9y3SG7zm31rE+2Ov6QoCCQ0CmnynF1O1HqDHEYhz4AFb0X2ujYHa4nvunrVTwW
JxsTyKwCbBZGYHNspBxtdCOCxQphqIq5nKEjebQJyXLwLgEeJnyTAFIUeGAQvWZg
dVBC8LAXp7C5aQba9vW+G4q7j58Tv2Jb0Al6Ovk1ZQTMi1oSWNCsATI45RrHWr5q
kC2NRhwTMU7JNrQKndy+co/EjX/aXlrvzxBrTZ8vBCJdQS4LQZGaVFu2yijWaSCW
T26v7dCLeIMVhjZnkzDe1Afr7sc5GsE/0WV02Sr0iTpaq57OfrI=
=c/L4
-----END PGP SIGNATURE-----
-->
