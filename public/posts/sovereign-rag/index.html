<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="Building My Own Sovereign RAG for Secure Code Analysis"><meta property="og:description" content="Building My Own Sovereign RAG for Secure Code Analysis
Lately, I‚Äôve been taking a closer look at some code analysis tools that claim to detect security vulnerabilities in software projects. The idea itself is solid. I got one of these tools recommended to me and decided to dig deeper to see what‚Äôs really behind these solutions.
Pretty quickly I noticed a pattern: these platforms are far from cheap. Some offer limited free plans, but we all know how this game works. When something that good is offered for ‚Äúfree‚Äù, the real price usually comes from somewhere else ‚Äî data collection, vendor lock-in, black-box models processing your code in someone else‚Äôs cloud. And since I‚Äôve been deeply studying AI lately, especially Retrieval-Augmented Generation (RAG), the question came naturally: why not build my own pipeline, fully local, sovereign, using open-source tools, running on my own machine, and depending on no one?"><meta property="og:url" content="https://adlermedrado.com.br/posts/sovereign-rag/"><meta property="og:site_name" content="Adler Medrado's corner of the web"><meta property="og:type" content="article"><meta property="og:image" content="/images/default-og-image.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Building My Own Sovereign RAG for Secure Code Analysis"><meta name=twitter:description content="Building My Own Sovereign RAG for Secure Code Analysis
Lately, I‚Äôve been taking a closer look at some code analysis tools that claim to detect security vulnerabilities in software projects. The idea itself is solid. I got one of these tools recommended to me and decided to dig deeper to see what‚Äôs really behind these solutions.
Pretty quickly I noticed a pattern: these platforms are far from cheap. Some offer limited free plans, but we all know how this game works. When something that good is offered for ‚Äúfree‚Äù, the real price usually comes from somewhere else ‚Äî data collection, vendor lock-in, black-box models processing your code in someone else‚Äôs cloud. And since I‚Äôve been deeply studying AI lately, especially Retrieval-Augmented Generation (RAG), the question came naturally: why not build my own pipeline, fully local, sovereign, using open-source tools, running on my own machine, and depending on no one?"><meta name=twitter:image content="/images/default-og-image.png"><title>Building My Own Sovereign RAG for Secure Code Analysis</title><meta name=description content="Building My Own Sovereign RAG for Secure Code Analysis
Lately, I‚Äôve been taking a closer look at some code analysis tools that claim to detect security vulnerabilities in software projects. The idea itself is solid. I got one of these tools recommended to me and decided to dig deeper to see what‚Äôs really behind these solutions.
Pretty quickly I noticed a pattern: these platforms are far from cheap. Some offer limited free plans, but we all know how this game works. When something that good is offered for ‚Äúfree‚Äù, the real price usually comes from somewhere else ‚Äî data collection, vendor lock-in, black-box models processing your code in someone else‚Äôs cloud. And since I‚Äôve been deeply studying AI lately, especially Retrieval-Augmented Generation (RAG), the question came naturally: why not build my own pipeline, fully local, sovereign, using open-source tools, running on my own machine, and depending on no one?"><link rel=author href=/humans.txt><link rel=icon type=image/png href=/images/favicon.png><link rel=canonical href=https://adlermedrado.com.br/posts/sovereign-rag/><link href=/css/styles.css rel=stylesheet></head><body><header class=glitch-zone><nav class=navbar role=navigation aria-label="Main Navigation"><div class=navbar_left><a href=/ class=h-card rel=me><strong>Adler Medrado<span class=cursor-blink>|</span></strong></a></div><div class="navbar_right navbar_right_animated"><a href=/about>about</a>
<a href=/projects>projects</a>
<a href=/posts>posts</a>
<a href=/missives>missives</a>
<a href=/now>what am i doing now</a>
<a href=/uses>what am i using</a>
<a href=/contact>contact</a></div></nav></header><main><section class=section><article><div><h1>Building My Own Sovereign RAG for Secure Code Analysis</h1><div><div><p><small><time>June 14, 2025</time>
|
7 minutes read</small><div class=post-tags><p><strong>Tags:</strong>
<a href=/tags/ai>ai</a>,
<a href=/tags/sovereign>sovereign</a>,
<a href=/tags/ollama>ollama</a>,
<a href=/tags/llm>llm</a>,
<a href=/tags/rag>rag</a>,
<a href=/tags/security>security</a></p></div></p></div><span class=line_break></span></div><div class=content><h2 id=building-my-own-sovereign-rag-for-secure-code-analysis>Building My Own Sovereign RAG for Secure Code Analysis</h2><p>Lately, I‚Äôve been taking a closer look at some code analysis tools that claim to detect security vulnerabilities in software projects. The idea itself is solid. I got one of these tools recommended to me and decided to dig deeper to see what‚Äôs really behind these solutions.</p><p>Pretty quickly I noticed a pattern: these platforms are far from cheap. Some offer limited free plans, but we all know how this game works. When something that good is offered for ‚Äúfree‚Äù, the real price usually comes from somewhere else ‚Äî data collection, vendor lock-in, black-box models processing your code in someone else‚Äôs cloud. And since I‚Äôve been deeply studying AI lately, especially Retrieval-Augmented Generation (RAG), the question came naturally: why not build my own pipeline, fully local, sovereign, using open-source tools, running on my own machine, and depending on no one?</p><p>That‚Äôs how <a href=https://github.com/spacexnu/sovereign-rag>SovereignRAG</a> was born.</p><h3 id=how-it-works>How it works</h3><p>The core idea was simple: feed my RAG with strong technical knowledge from reputable security sources. I went straight to materials like OWASP Top 10, CWE, NIST, and other well-established security references. From there, I followed this strategy:</p><ol><li>Collect the original sources in PDF format (OWASP Top 10, CWE, NIST, etc).</li><li>Build a parser to extract text from these PDFs. To clean the data, I used NLP with spaCy, removing noise and filtering only what really matters. The processed data is then stored into ChromaDB as a vector store.</li><li>Develop a specific prompt, initially hardcoded into the project. My next step is to make this more dynamic and flexible, allowing the tool to adapt to different use cases and projects.</li><li>As language model, I‚Äôm running Ollama locally with the mistral:7b-instruct model. It‚Äôs not a gigantic model, but it‚Äôs also not as limited as the phi3-instruct I tested earlier. Given my hardware limitations, it was the best balance I found.</li></ol><p>Everything runs entirely on my personal MacBook Air M1 with 16GB of RAM. Obviously, this isn‚Äôt instantaneous. Local LLM inference is CPU intensive, especially when dealing with long inputs and dense technical context. But the main point of the experiment is proven: it‚Äôs fully possible to run a sovereign RAG pipeline, offline, keeping all data under my full control, without sending anything to any cloud, and especially, without paying absurd SaaS prices for these so-called ‚Äúintelligent‚Äù solutions popping up everywhere.</p><p>I already have several improvements in mind. Parallelism isn‚Äôt one of them for now ‚Äî I don‚Äôt plan to burn my Mac‚Äôs SSD swapping like there‚Äôs no tomorrow.</p><h3 id=technical-architecture>Technical Architecture</h3><p>Since the main goal was always full control of the pipeline, I designed the SovereignRAG architecture to be modular, with each step clearly separated and built entirely on open-source tools I can fully manage locally. No external dependencies.</p><p>The pipeline works like this:</p><p><strong>1. Ingesting security documents</strong></p><p>The first step was collecting and processing the knowledge base that feeds the RAG. I used official security documentation in PDF format, including OWASP Top 10, CWE, and NIST. For text extraction, I used PyMuPDF to parse the PDFs and spaCy to clean up, tokenize, and remove irrelevant content. This stage matters because unnecessary noise directly affects the quality of embeddings generated later.</p><p><strong>2. Embeddings and vector indexing</strong></p><p>Once the content was cleaned, I used the all-MiniLM-L6-v2 model from SentenceTransformers to generate embeddings. These vectors were stored into ChromaDB, a lightweight and efficient vector database that runs smoothly on local hardware without any crazy requirements.</p><p><strong>3. Querying and code analysis</strong></p><p>For code analysis, the pipeline reads the source file, injects its contents into the pre-defined prompt, retrieves the most relevant documents from the vector store (top_k carefully controlled to avoid overloading the model), and triggers inference.</p><p>The inference runs locally via Ollama using the mistral:7b-instruct model. This model has been the best balance I found between reasoning capacity, longer context window support, and practical viability on my limited hardware.</p><p><strong>4. Report generation</strong></p><p>Instead of dumping everything to the terminal, I added HTML report generation for each analyzed file. This allows me to review results more easily and opens the door for building a proper web interface in the future.</p><h3 id=challenges-limitations-and-lessons-learned>Challenges, Limitations, and Lessons Learned</h3><p>Of course, there‚Äôs no magic here. Running a sovereign, offline, local RAG pipeline for secure code analysis over complex security knowledge bases comes with very real challenges. This is not some SaaS plug-and-play solution, and it‚Äôs definitely not for everyone.</p><p>The first thing that hits immediately is hardware itself. LLMs are heavy. I‚Äôm running this on a MacBook Air M1 with 16GB of RAM ‚Äî which is a great machine for a lot of things, but it‚Äôs absolutely not designed for large-scale AI inference workloads. This forced me to make very pragmatic decisions from the start: fully serial processing (one file at a time), strict control over context size (carefully tuned top_k), aggressive chunking during ingestion, and absolutely no parallelism. Trying to parallelize this would simply turn into thermal suicide and unnecessary SSD wear from constant swapping.</p><p>Another important challenge is how LLMs behave when receiving dense technical context. I learned quickly that you can‚Äôt just inject entire documentation dumps and expect the model to figure everything out. There‚Äôs careful prompt engineering involved here to guide the model into the right path without overwhelming it with unnecessary noise.</p><p>There‚Äôs also a constant balancing act between embedding quality and local inference performance. The MiniLM model was a good starting point to generate compact and efficient embeddings, but I already see room to experiment with more advanced models like BGE and Instructor in future iterations.</p><p>And of course, the most obvious challenge: speed. You can‚Äôt run this locally and expect instant responses, especially with 7B models. Every analysis takes time. This isn‚Äôt something you plug into a CI/CD pipeline (yet), but as a sovereign lab and proof of concept, it performs its job exactly as intended.</p><img height=50% src=/posts/images/sovereign-rag.png width=50%><h3 id=next-steps-and-evolution>Next steps and evolution</h3><p>SovereignRAG started as a lab experiment, but it‚Äôs already pointing toward interesting expansion paths. The current architecture works well to validate the concept of sovereign RAG applied to secure code analysis, but there are several layers of improvements I plan to introduce.</p><p>The first target is refining chunking during document ingestion. This is one of the most critical aspects of any RAG pipeline. Wrong chunking equals wrong context. There‚Äôs a fine balance to strike here between chunk granularity, embedding quality, and vector store recall capacity.</p><p>Embeddings are another natural evolution point. Today I‚Äôm using all-MiniLM-L6-v2 because of its lightweight footprint and practical viability on my current setup, but I‚Äôm keeping an eye on more advanced models like BGE and Instructor, which might generate more precise semantic embeddings for this type of data.</p><p>On the inference side, there‚Äôs room to explore additional models beyond mistral:7b-instruct. Eventually I may test Mixtral or experiment with optimized quantization approaches to improve performance on limited hardware. I‚Äôm also not discarding the idea of building a dedicated sovereign server later to handle these workloads more fluidly, preserving my MacBook for development and content production.</p><p>Another short-term goal is making the pipeline more flexible and configurable. Right now the prompt is hardcoded into the codebase. The plan is to externalize this configuration, allow for easier adjustments, and even implement template-based analysis for different project types or languages.</p><p>Finally, the bigger move over the mid-term is evolving what today is a lab into a real product. SovereignRAG already serves as a foundation for what could become CodeTalon ‚Äî a professional, private, offline, sovereign secure code analysis product for corporate environments, free from third-party APIs, shadow clouds, or overpriced SaaS traps.</p><p>The concept is planted. Now it‚Äôs a matter of refining the machine and sharpening the blade.</p><p><img src=/posts/images/sovereign-rag-faster.gif alt=gif-version-of-video-running-the-rag></p></div></div></article><div><div><div><a href=https://adlermedrado.com.br/posts/rag_soberano/>&#8592; Como constru√≠ meu pr√≥prio RAG soberano para an√°lise de seguran√ßa de c√≥digo</a>
|
<a href=https://adlermedrado.com.br/posts/fraudtalon-mvp/>Fighting online fraud with FraudTalon &#8594;</a></div></div></div></section></main><footer class=glitch-zone role=contentinfo><div class=footer-content><div class=copyright><p><small>&copy; 1996-2025 Adler Medrado</small></p></div><div class=gpg_signed_info><div class=gpg-callout><div class=gpg-callout__icon aria-hidden=true>üîè</div><div class=gpg-callout__text><p class=gpg-callout__title>All pages are PGP signed.</p><p class=gpg-callout__subtitle>Learn how to verify my PGP signature <a class=gpg-callout__link href=/posts/verify-signatures>here</a>.</p></div></div><p><em>Privacy policy: this website employs no tracking.</em></p><p><span class=badge-a-plus><a href="https://developer.mozilla.org/en-US/observatory/analyze?host=adlermedrado.com.br" aria-label="Mozilla Observatory Security Rating: A+">A+</a></span>
<span class=badge-description>Mozilla Observatory Security Rating</span></p></div></div></footer></body></html>