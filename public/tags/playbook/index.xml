<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Playbook on Adler Medrado's corner of the web</title><link>https://adlermedrado.com.br/tags/playbook/</link><description>Recent content in Playbook on Adler Medrado's corner of the web</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 16 Jun 2025 20:25:44 -0300</lastBuildDate><atom:link href="https://adlermedrado.com.br/tags/playbook/index.xml" rel="self" type="application/rss+xml"/><item><title>Ollama Local AI Playbook</title><link>https://adlermedrado.com.br/missives/ollama-local-ai-playbook/</link><pubDate>Mon, 16 Jun 2025 20:25:44 -0300</pubDate><guid>https://adlermedrado.com.br/missives/ollama-local-ai-playbook/</guid><description>&lt;p&gt;Running AI models locally on your Mac M1 is easier than you think.&lt;/p&gt;
&lt;p&gt;No cloud. No expensive subscriptions. No unnecessary complexity. Just your own hardware and full control.&lt;/p&gt;
&lt;p&gt;I just released a 30-minute playbook that shows exactly how to run Ollama fully local on Mac M1:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Full install guide&lt;/li&gt;
&lt;li&gt;Copy-paste terminal commands&lt;/li&gt;
&lt;li&gt;Model recommendations tested on M1 hardware&lt;/li&gt;
&lt;li&gt;Performance optimization tips&lt;/li&gt;
&lt;li&gt;Local security checklist&lt;/li&gt;
&lt;li&gt;Bonus cheat sheet included&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Launch price: $5&lt;/strong&gt;&lt;/p&gt;</description></item></channel></rss>