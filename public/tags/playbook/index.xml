<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Playbook on Adler Medrado's corner of the web</title><link>https://adlermedrado.com.br/tags/playbook/</link><description>Recent content in Playbook on Adler Medrado's corner of the web</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 16 Jun 2025 20:25:44 -0300</lastBuildDate><atom:link href="https://adlermedrado.com.br/tags/playbook/index.xml" rel="self" type="application/rss+xml"/><item><title>Ollama Local AI Playbook</title><link>https://adlermedrado.com.br/missives/ollama-local-ai-playbook/</link><pubDate>Mon, 16 Jun 2025 20:25:44 -0300</pubDate><guid>https://adlermedrado.com.br/missives/ollama-local-ai-playbook/</guid><description>&lt;p>Running AI models locally on your Mac M1 is easier than you think.&lt;/p>
&lt;p>No cloud. No expensive subscriptions. No unnecessary complexity. Just your own hardware and full control.&lt;/p>
&lt;p>I just released a 30-minute playbook that shows exactly how to run Ollama fully local on Mac M1:&lt;/p>
&lt;ul>
&lt;li>Full install guide&lt;/li>
&lt;li>Copy-paste terminal commands&lt;/li>
&lt;li>Model recommendations tested on M1 hardware&lt;/li>
&lt;li>Performance optimization tips&lt;/li>
&lt;li>Local security checklist&lt;/li>
&lt;li>Bonus cheat sheet included&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Launch price: $5&lt;/strong>&lt;/p></description></item></channel></rss>